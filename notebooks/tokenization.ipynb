{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFcv-PqWUu87"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nkthiebaut/guanaco/blob/main/notebooks/tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "# Tokenization\n",
        "\n",
        "## Character encodings: Unicode and UTF-8\n",
        "\n",
        "From https://docs.python.org/3/howto/unicode.html\n",
        "\n",
        "‚Äú[Unicode is a] [...] specification that aims to list every character used by human languages and give each character its own unique code. [...] characters are represented by code points. A code point value is an integer in the range 0 to 0x10FFFF (about 1.1 million values [of which ~100k are currently assigned])‚Äù\n",
        "\n",
        "Codepoint to glyph (the \"drawing\" of a character) conversion is handled by the GUI toolkit or a terminal‚Äôs font renderer (uses system typeface and fonts).\n",
        "\n",
        "Unicode encodes strings as series of code points:\n",
        "```\n",
        "‚ÄúMSDS‚Äù ‚Üí [U+004D, U+0053, U+0044, U+0053]\n",
        "```\n",
        "Unicode Transformation Format (UTF) defines how to represent these in memory using code units. It comes in 3 flavors: UTF-8, UTF-16, UTF-32. UTF-8 is by far the most common.\n",
        "\n",
        "For ASCII character (code point < 128), ASCII-code, Unicode code point, and UTF-8 representation are all the same. For example \"a\" is 97 (decimal) / 0x61 (hexadecimal) / 0b1100001 (binary)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9tLzlK9Ys4c",
        "outputId": "c182eb5d-0637-41dc-fb69-3d3f194ada11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Code point for a: 97 (dec) / 0x61 (hex)\n"
          ]
        }
      ],
      "source": [
        "char = \"a\"\n",
        "code_point = ord(char)\n",
        "print(f\"Code point for {char}: {code_point} (dec) / {hex(code_point)} (hex)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXeb7Jx8Zuor",
        "outputId": "08a7b9f5-452d-4bdc-fe40-bc2c34acbf49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UTF-8 code units: b'a' -> ['0b1100001']\n"
          ]
        }
      ],
      "source": [
        "code_units = char.encode(\"utf-8\")\n",
        "print(f\"UTF-8 code units: {code_units} -> {list(map(bin, code_units))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-X9D6UnfXba"
      },
      "source": [
        "For all characters beyond the ASCII table (i.e. all non-English languages, emojis, math symbols, ...), UTF-8 uses **variable-length encoding** from 8 to 32 bits. For example for the \"üòâ\" character the Unicode code point is larger than 128, hence it is encoded with several code units.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUonN6gbakdv",
        "outputId": "e8d52fd3-9753-4f24-bacf-7675b3462cef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Code point for üòâ: 128521 (dec) / 0x1f609 (hex)\n"
          ]
        }
      ],
      "source": [
        "char = \"üòâ\"\n",
        "code_point = ord(char)\n",
        "print(f\"Code point for {char}: {code_point} (dec) / {hex(code_point)} (hex)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pKWhJdXarLP",
        "outputId": "6eabb5bc-41f5-47ef-aea2-f08f726c792d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UTF-8 code units: b'\\xf0\\x9f\\x98\\x89' -> ['0b11110000', '0b10011111', '0b10011000', '0b10001001']\n"
          ]
        }
      ],
      "source": [
        "code_units = char.encode(\"utf-8\")\n",
        "print(f\"UTF-8 code units: {code_units} -> {list(map(bin, code_units))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_hoNraX4i7R7",
        "outputId": "2d943804-04dd-41d1-f538-20173a5e08e3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0b11111011000001001'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bin(128521)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdG6F0mf2hSZ"
      },
      "source": [
        "In the code units sequence, bytes starting with:\n",
        "- `11110` indicate the beginning of a 4 bytes sequence\n",
        "- `1110` indicate the beginning of a 3 bytes sequence\n",
        "- `110` indicate the beginning of a 2 bytes sequence\n",
        "- `0` indicate a single-byte encoding (ASCII character)\n",
        "\n",
        "Bytes starting with `10` are follow-up bytes in a longer sequence.\n",
        "\n",
        "‚ö†Ô∏è The UTF-8 code unit sequence (`0xf0 0x9f 0x98 0x89 = 11110000 10011111 10011000 10001001` in the last example) is different from the corresponding Unicode code point (`0x1f609 = 11111011000001001` for the last example). Also, not all valid UTF-8 correspond to assigned Unicode code points.\n",
        "\n",
        "üìù _Exercise_: how many characters are encoded by the following sequence code units:\n",
        "\n",
        "```01000011 01100001 01100110 11000011 10101001```\n",
        "\n",
        "and this one:\n",
        "\n",
        "```11110000 10011111 10001100 10001101```?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hTpLu5OXQGP"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4Y9wXkskH3U",
        "outputId": "e36f0a58-52e3-4910-a0f0-31d0c41b0401"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[15339, 1917, 264, 70540, 33746]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pip install -q tiktoken\n",
        "import tiktoken\n",
        "\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
        "token_ids = encoding.encode(\"hello world aaaaaaaaaaaa\")\n",
        "token_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "08oW_zZ_AbZH",
        "outputId": "bc2b976c-9909-4d1f-a577-c036490552e2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'hello world aaaaaaaaaaaa'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoding.decode(token_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ij09HBYgAmjA",
        "outputId": "7b1f1b05-bbfe-4a54-a364-156ea9738383"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token ID: 15339, Token: hello\n",
            "Token ID: 1917, Token:  world\n",
            "Token ID: 264, Token:  a\n",
            "Token ID: 70540, Token: aaaaaaaa\n",
            "Token ID: 33746, Token: aaa\n"
          ]
        }
      ],
      "source": [
        "# Decode the token IDs to get the tokens\n",
        "tokens = [encoding.decode_single_token_bytes(token_id) for token_id in token_ids]\n",
        "\n",
        "# Display the token IDs and their corresponding tokens\n",
        "for token_id, token in zip(token_ids, tokens):\n",
        "    print(f\"Token ID: {token_id}, Token: {token.decode('utf-8', errors='replace')}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxbwig8jA5Y4"
      },
      "source": [
        "Check https://tiktokenizer.vercel.app/ for a Tiktoken visualization."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
